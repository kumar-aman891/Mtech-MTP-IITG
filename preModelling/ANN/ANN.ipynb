{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3appgMXMtkh"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "C_NSuVD-Mtko"
      },
      "source": [
        "Part 1 : Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "gRfvIBFjMtkp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAJ4WYAssrvW",
        "outputId": "8002edfe-22c5-4027-c4cd-109402f9b804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace Excel_data/Top_setting.xlsx? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#first we need to extract the zip data present in our drive\n",
        "!unzip drive/MyDrive/DataPre.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOlYjlSRNI6_",
        "outputId": "1d3ed80e-71f4-42bd-f05a-59631be85452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['28', '36', '31', '50', '5', '96', '117', '77', '46', '48', '21', '62', '13', '110', '51', '100', '81', '23', '93', '16', '45', '1', '26', '66', '20', '82', '118', '106', '29', '80', '39', '75', '30', '64', '108', '92', '41', '3', '37', '84', '85', '42', '19', '4', '61', '89', '107', '73', '33', '78', '44', '116', '111', '105', '52', '6', '98', '99', '67', '65', '113', '69', '114', '38', '63', '11', '57', '90', '55', '104', '91', '97', '88', '40', '72', '9', '95', '119', '74', '43', '15', '49', '87', '7', '86', '70', '102', '101', '22', '2', '35', '27', '60', '8', '47', '112', '76', '32', '115', '56', '18', '71', '79', '34', '59', '12', '54', '109', '94', '17', '120', '14', '10', '103', '58', '68', '25', '53', '24', '83']\n"
          ]
        }
      ],
      "source": [
        "#loading images\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import glob\n",
        "image_list = [] # will contain all the images in the rspective location\n",
        "name = [] # will contain the name of respective images so that respective topology setting could be fetched from excel\n",
        "for filename in glob.glob('/content/img/*.png'): #assuming gif\n",
        "    im=Image.open(filename)\n",
        "    name.append(filename)\n",
        "    image_list.append(im)\n",
        "\n",
        "numerics = []\n",
        "for i in range(len(name)):\n",
        "  a_string = name[i]\n",
        "  numeric_filter = filter(str.isdigit, a_string)\n",
        "  numeric_string = \"\".join(numeric_filter)\n",
        "  numerics.append(numeric_string)\n",
        "\n",
        "print(numerics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nVk_CPcvp5M",
        "outputId": "57591e94-40d1-4f4b-dc58-d976750ce6cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "execution_count": 305,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "hgqbI7hnudYS"
      },
      "outputs": [],
      "source": [
        "#both image_list and numerics have 120 elements but their indexing starts from 0 hence last element is at index 119\n",
        "#now lets convert our image_list array to a numpy array\n",
        "\n",
        "\n",
        "# # example of converting an image with the Keras API\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "\n",
        "#the following loop will convert each elements (each images) to a numpy array  and resizing \n",
        "for i in range(len(image_list)):\n",
        "  image_list[i] = img_to_array(image_list[i])\n",
        "  # image_list[i]=np.resize(image_list[i],(800,800,3))\n",
        "  \n",
        "#follwoing line will convert the list to a numpy array with 120 elements and each element in respective size RGB\n",
        "imgArr = np.array(image_list)\n",
        "\n",
        "# for i in range(len(image_list)):\n",
        "#   imgNpArr[i] = [img_to_array(image_list[i])]\n",
        "\n",
        "\n",
        "# print(\"type:\",img_array.dtype)\n",
        "# print(\"shape:\",img_array.shape)\n",
        "# # convert back to image\n",
        "\n",
        "# img_pil = array_to_img(img_array)\n",
        "# print(\"converting NumPy array:\",type(img_pil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRcHOAZMD70E",
        "outputId": "e2bc93b3-2df4-491b-d676-f45657a6a694"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(656, 875, 3)"
            ]
          },
          "execution_count": 307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_list[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "o4EUKyo5ILWu",
        "outputId": "102d8183-2009-429f-eaf6-a39d7c4478d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff5a7b38d50>"
            ]
          },
          "execution_count": 308,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(image_list[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1cMjUz9wt8e",
        "outputId": "264c5bee-3345-4799-9ee4-38a51fe59370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Volfrac  Fy  Fx  Images\n",
            "0        0.4  10  10       1\n",
            "1        0.4   9   9       2\n",
            "2        0.4   8   8       3\n",
            "3        0.4   7   7       4\n",
            "4        0.4   6   6       5\n",
            "..       ...  ..  ..     ...\n",
            "115      0.6   5 -15     116\n",
            "116      0.6   4 -12     117\n",
            "117      0.6   3  -9     118\n",
            "118      0.6   2  -6     119\n",
            "119      0.6   1  -3     120\n",
            "\n",
            "[120 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "#now lets bring in the excel data file\n",
        "dataset = pd.read_excel('/content/Excel_data/Top_setting.xlsx')\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "P8upW2VM0TSz"
      },
      "outputs": [],
      "source": [
        "#making of dependent and independent variables\n",
        "x = dataset.iloc[:,:].values\n",
        "xx = []\n",
        "for i in range(0,len(numerics)):\n",
        "  xx.append(x[int(numerics[i])-1])\n",
        "x = xx #This will make elements of x in sync with the image array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z53nKGcS473c",
        "outputId": "258db709-60ed-4564-93d1-a7b716275978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        " x = np.array(x)\n",
        " print(type(x))\n",
        " print(type(imgArr))\n",
        " #Now we have our input array and output array\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4leFUlCJpg",
        "outputId": "f4edb64c-b2fa-4a7e-a9e5-65527d6f46d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(120, 656, 875, 3)"
            ]
          },
          "execution_count": 313,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imgArr.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cyRJv2pE_Nu",
        "outputId": "0f3e6277-8c02-4b4e-f37d-7848f6be107b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(120, 1722000)"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Flattening the each image in imgArr so that each element will be a single column of nodes = 656*875*3\n",
        "# flat_gfg = gfg.flatten()\n",
        "#making a yArr which has dimension as (120,656*875*3) and then equating each element of it to the flattened image in next loop\n",
        "yArr = imgArr\n",
        "yArr = np.ndarray.reshape(yArr,(-1,656*875*3))\n",
        "\n",
        "for i in range(imgArr.shape[0]):\n",
        "  yArr[i] = imgArr[i].flatten()\n",
        "yArr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "3LrnI0pqFsIQ"
      },
      "outputs": [],
      "source": [
        "#eliminating the 4th column in the x as now the input and output values are in sync so we dont require serial number.\n",
        "x_final = []\n",
        "# \n",
        "\n",
        "for i in range(x.shape[0]):\n",
        "  x_final.append([x[i][0],x[i][1],x[i][2]])\n",
        "x_final = np.array(x_final) \n",
        "\n",
        "#Now making the train test split\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "x_train , x_test , y_train , y_test = tts(x_final, yArr, test_size = 0.2, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmO4aPDpMSC5",
        "outputId": "39f275bb-c833-4f7e-b85c-9a43cb2b95e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(96, 3)\n",
            "(24, 3)\n",
            "(96, 1722000)\n",
            "(24, 1722000)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BncQmqFhM0y2",
        "outputId": "a637cfc1-71a1-4dcd-ca93-e7e3760baa78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKfmDRlrMtkx"
      },
      "source": [
        "Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "id": "_d3zccUvMtkx"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1gVfE_MMtky"
      },
      "source": [
        "Part 2 : Building ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "id": "4usjmzfkMtky"
      },
      "outputs": [],
      "source": [
        "#Initializing ANN\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "#adding the input layer and the first hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units =6 , activation = 'relu',input_shape = (3,)))\n",
        "\n",
        "#adding the second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units =6 , activation = 'relu'))\n",
        "\n",
        "#adding the output layer\n",
        "ann.add(tf.keras.layers.Dense(units =1722000 , activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxGX3MpdMtky"
      },
      "source": [
        "Part 3 : Training The ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "id": "sJiPM4FoMtkz"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV3xlDRWMtkz"
      },
      "source": [
        "Training the ANN on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhvd1FFFMtkz",
        "outputId": "66b3a0fe-56cc-4032-ef2c-7dda8261d60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(96, 3)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 6)                 24        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1722000)           12054000  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,054,066\n",
            "Trainable params: 12,054,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "ann.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "7ujNencVMtkz",
        "outputId": "982e458a-637c-4382-9629-e5f2d515731b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 5s 1s/step - loss: 5470178304.0000 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5470084096.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 3s 925ms/step - loss: 5469985280.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 3s 918ms/step - loss: 5469882368.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5469772800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5469660160.0000 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 3s 940ms/step - loss: 5469541376.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5469414912.0000 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5469287936.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5469149184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 3s 997ms/step - loss: 5469007360.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 3s 931ms/step - loss: 5468856320.0000 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 3s 949ms/step - loss: 5468704256.0000 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 3s 916ms/step - loss: 5468546560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/3 [===================>..........] - ETA: 1s - loss: 5478981632.0000 - accuracy: 0.0000e+00"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-365-ebb1681a92ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ann.fit(x_train, y_train,batch_size = 32 , epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jJlPrApMtk0"
      },
      "source": [
        "Making the prediction and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaEiz8tMtk1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
